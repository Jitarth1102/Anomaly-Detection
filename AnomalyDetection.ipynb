{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-23T12:26:58.993768Z","iopub.status.busy":"2024-09-23T12:26:58.993410Z","iopub.status.idle":"2024-09-23T12:27:19.491321Z","shell.execute_reply":"2024-09-23T12:27:19.490381Z","shell.execute_reply.started":"2024-09-23T12:26:58.993739Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyod\n","  Downloading pyod-2.0.2.tar.gz (165 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.8/165.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\n","Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from pyod) (1.4.2)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from pyod) (3.7.5)\n","Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from pyod) (1.26.4)\n","Requirement already satisfied: numba>=0.51 in /opt/conda/lib/python3.10/site-packages (from pyod) (0.58.1)\n","Requirement already satisfied: scipy>=1.5.1 in /opt/conda/lib/python3.10/site-packages (from pyod) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from pyod) (1.2.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.59.3)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n","Collecting keras\n","  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51->pyod) (0.41.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->pyod) (3.2.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (2.9.0.post0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pyod\n","  Building wheel for pyod (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pyod: filename=pyod-2.0.2-py3-none-any.whl size=198478 sha256=842f1aed5a90248d7e906e7aed62ea14cec9d688ca0ec3e4a5d1801dc172f84b\n","  Stored in directory: /root/.cache/pip/wheels/77/c2/20/34d1f15b41b701ba69f42a32304825810d680754d509f91391\n","Successfully built pyod\n","Installing collected packages: keras, pyod\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.3.3\n","    Uninstalling keras-3.3.3:\n","      Successfully uninstalled keras-3.3.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.15.0 pyod-2.0.2\n"]}],"source":["!pip install pyod tensorflow keras"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-23T12:27:19.493330Z","iopub.status.busy":"2024-09-23T12:27:19.493007Z","iopub.status.idle":"2024-09-23T12:27:32.765466Z","shell.execute_reply":"2024-09-23T12:27:32.764486Z","shell.execute_reply.started":"2024-09-23T12:27:19.493301Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-23 12:27:22.948552: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-23 12:27:22.948653: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-23 12:27:23.072889: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["/kaggle/input/dataset1/Dataset 1 .csv\n","/kaggle/input/dataset-1/Dataset_1.csv\n","/kaggle/input/dataset2/Dataset 2 .csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","import numpy as np\n","import pandas as pd\n","from pyod.models.knn import KNN\n","from matplotlib import pyplot as plt\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.gaussian_process import GaussianProcessRegressor\n","from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.pipeline import make_pipeline\n","from tensorflow.keras.layers import LSTM\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, RepeatVector, TimeDistributed\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:27:32.767181Z","iopub.status.busy":"2024-09-23T12:27:32.766596Z","iopub.status.idle":"2024-09-23T12:27:34.229005Z","shell.execute_reply":"2024-09-23T12:27:34.228107Z","shell.execute_reply.started":"2024-09-23T12:27:32.767152Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>P1</th>\n","      <th>P2</th>\n","      <th>P3</th>\n","      <th>P4</th>\n","      <th>P5</th>\n","      <th>P6</th>\n","      <th>P7</th>\n","      <th>P8</th>\n","      <th>P9</th>\n","    </tr>\n","    <tr>\n","      <th>Datetime</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2011-10-15 00:39:53.093501721</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005420</td>\n","      <td>0.011201</td>\n","      <td>38.0</td>\n","      <td>52.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-15 00:40:13.547292334</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005400</td>\n","      <td>0.011177</td>\n","      <td>38.0</td>\n","      <td>52.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-15 00:40:34.001082947</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005387</td>\n","      <td>0.011188</td>\n","      <td>38.0</td>\n","      <td>52.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-15 00:40:54.454873560</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005420</td>\n","      <td>0.011160</td>\n","      <td>38.0</td>\n","      <td>52.300000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-15 00:41:14.908664173</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005371</td>\n","      <td>0.011160</td>\n","      <td>38.0</td>\n","      <td>52.454545</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:45:38.857581759</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>51.777778</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:45:52.715163726</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>51.833333</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:46:06.572745693</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>51.888889</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:46:20.430327660</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>51.944444</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:46:34.287909627</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>52.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 9 columns</p>\n","</div>"],"text/plain":["                                   P1      P2        P3        P4    P5  \\\n","Datetime                                                                  \n","2011-10-15 00:39:53.093501721 -0.0469 -0.0385  0.005420  0.011201  38.0   \n","2011-10-15 00:40:13.547292334 -0.0469 -0.0385  0.005400  0.011177  38.0   \n","2011-10-15 00:40:34.001082947 -0.0469 -0.0385  0.005387  0.011188  38.0   \n","2011-10-15 00:40:54.454873560 -0.0469 -0.0385  0.005420  0.011160  38.0   \n","2011-10-15 00:41:14.908664173 -0.0469 -0.0385  0.005371  0.011160  38.0   \n","...                               ...     ...       ...       ...   ...   \n","2011-10-25 03:45:38.857581759 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","2011-10-25 03:45:52.715163726 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","2011-10-25 03:46:06.572745693 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","2011-10-25 03:46:20.430327660 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","2011-10-25 03:46:34.287909627 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","\n","                                      P6   P7   P8   P9  \n","Datetime                                                 \n","2011-10-15 00:39:53.093501721  52.000000  0.0  0.0  0.0  \n","2011-10-15 00:40:13.547292334  52.000000  0.0  0.0  0.0  \n","2011-10-15 00:40:34.001082947  52.000000  0.0  0.0  0.0  \n","2011-10-15 00:40:54.454873560  52.300000  0.0  0.0  0.0  \n","2011-10-15 00:41:14.908664173  52.454545  0.0  0.0  0.0  \n","...                                  ...  ...  ...  ...  \n","2011-10-25 03:45:38.857581759  51.777778  0.0  0.0  0.0  \n","2011-10-25 03:45:52.715163726  51.833333  0.0  0.0  0.0  \n","2011-10-25 03:46:06.572745693  51.888889  0.0  0.0  0.0  \n","2011-10-25 03:46:20.430327660  51.944444  0.0  0.0  0.0  \n","2011-10-25 03:46:34.287909627  52.000000  0.0  0.0  0.0  \n","\n","[50000 rows x 9 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Load the data\n","df = pd.read_csv(\"/kaggle/input/dataset2/Dataset 2 .csv\", nrows=50000)\n","\n","# Convert 'Datetime' column to datetime format\n","df['Datetime'] = pd.to_datetime(df['Date\\t'] + ' ' + df['Time'], format='%d-%m-%Y %M:%S.%f')\n","df.set_index('Datetime', inplace=True)\n","df.drop(['Date\\t', 'Time'], axis=1, inplace=True)\n","\n","cumulative_hour_diff = 0\n","prev_minute = df.index[0].minute\n","prev_date = df.index[0].date()\n","\n","# Adjust for non-uniform sampling\n","def adjust_hour(index):\n","    global cumulative_hour_diff, prev_minute, prev_date\n","    if index.date() != prev_date:\n","        cumulative_hour_diff = 0  # Reset hour difference at the start of a new day\n","        prev_date = index.date()\n","    elif index.minute < prev_minute:\n","        cumulative_hour_diff += 1\n","    prev_minute = index.minute\n","    return index + pd.Timedelta(hours=cumulative_hour_diff)\n","\n","df.index = df.index.map(adjust_hour)\n","df = df.iloc[:50000, :]\n","def resample_and_interpolate(group):\n","    avg_time_diff = group.index.to_series().diff().mean()\n","    return group.resample(avg_time_diff).mean().interpolate(method='time')\n","\n","df = df.groupby(df.index.date).apply(resample_and_interpolate)\n","df.reset_index(level=0, drop=True, inplace=True)\n","df"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:27:34.231644Z","iopub.status.busy":"2024-09-23T12:27:34.231326Z","iopub.status.idle":"2024-09-23T12:27:34.253973Z","shell.execute_reply":"2024-09-23T12:27:34.252994Z","shell.execute_reply.started":"2024-09-23T12:27:34.231618Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>P1</th>\n","      <th>P2</th>\n","      <th>P3</th>\n","      <th>P4</th>\n","      <th>P5</th>\n","      <th>P6</th>\n","      <th>P7</th>\n","      <th>P8</th>\n","      <th>P9</th>\n","    </tr>\n","    <tr>\n","      <th>Datetime</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2011-10-15 00:39:53.093501721</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005420</td>\n","      <td>0.011201</td>\n","      <td>38.0</td>\n","      <td>52.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-15 00:40:13.547292334</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005400</td>\n","      <td>0.011177</td>\n","      <td>38.0</td>\n","      <td>52.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-15 00:40:34.001082947</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005387</td>\n","      <td>0.011188</td>\n","      <td>38.0</td>\n","      <td>52.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-15 00:40:54.454873560</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005420</td>\n","      <td>0.011160</td>\n","      <td>38.0</td>\n","      <td>52.300000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-15 00:41:14.908664173</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005371</td>\n","      <td>0.011160</td>\n","      <td>38.0</td>\n","      <td>52.454545</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:45:38.857581759</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>51.777778</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:45:52.715163726</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>51.833333</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:46:06.572745693</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>51.888889</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:46:20.430327660</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>51.944444</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2011-10-25 03:46:34.287909627</th>\n","      <td>-0.0469</td>\n","      <td>-0.0385</td>\n","      <td>0.005820</td>\n","      <td>0.011310</td>\n","      <td>37.0</td>\n","      <td>52.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 9 columns</p>\n","</div>"],"text/plain":["                                   P1      P2        P3        P4    P5  \\\n","Datetime                                                                  \n","2011-10-15 00:39:53.093501721 -0.0469 -0.0385  0.005420  0.011201  38.0   \n","2011-10-15 00:40:13.547292334 -0.0469 -0.0385  0.005400  0.011177  38.0   \n","2011-10-15 00:40:34.001082947 -0.0469 -0.0385  0.005387  0.011188  38.0   \n","2011-10-15 00:40:54.454873560 -0.0469 -0.0385  0.005420  0.011160  38.0   \n","2011-10-15 00:41:14.908664173 -0.0469 -0.0385  0.005371  0.011160  38.0   \n","...                               ...     ...       ...       ...   ...   \n","2011-10-25 03:45:38.857581759 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","2011-10-25 03:45:52.715163726 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","2011-10-25 03:46:06.572745693 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","2011-10-25 03:46:20.430327660 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","2011-10-25 03:46:34.287909627 -0.0469 -0.0385  0.005820  0.011310  37.0   \n","\n","                                      P6   P7   P8   P9  \n","Datetime                                                 \n","2011-10-15 00:39:53.093501721  52.000000  0.0  0.0  0.0  \n","2011-10-15 00:40:13.547292334  52.000000  0.0  0.0  0.0  \n","2011-10-15 00:40:34.001082947  52.000000  0.0  0.0  0.0  \n","2011-10-15 00:40:54.454873560  52.300000  0.0  0.0  0.0  \n","2011-10-15 00:41:14.908664173  52.454545  0.0  0.0  0.0  \n","...                                  ...  ...  ...  ...  \n","2011-10-25 03:45:38.857581759  51.777778  0.0  0.0  0.0  \n","2011-10-25 03:45:52.715163726  51.833333  0.0  0.0  0.0  \n","2011-10-25 03:46:06.572745693  51.888889  0.0  0.0  0.0  \n","2011-10-25 03:46:20.430327660  51.944444  0.0  0.0  0.0  \n","2011-10-25 03:46:34.287909627  52.000000  0.0  0.0  0.0  \n","\n","[50000 rows x 9 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Advanced interpolation using Gaussian Process Regression\n","def interpolate_with_gpr_batch(data, batch_size=25000):\n","    gp_data = []\n","    num_batches = int(np.ceil(len(data) / batch_size))\n","    kernel = C(1.0, (1e-4, 1e1)) * RBF(1.0, (1e-4, 1e1))\n","    for col in data.columns:\n","        y_pred_total = []\n","        for batch_num in range(num_batches):\n","            print(batch_num+1)\n","            start_idx = batch_num * batch_size\n","            end_idx = min(start_idx + batch_size, len(data))\n","            batch_data = data.iloc[start_idx:end_idx]\n","            \n","            X = np.array(batch_data.index.astype(int)).reshape(-1, 1)\n","            y = batch_data[col].values\n","\n","            # Initialize and fit Gaussian Process Regressor\n","            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=1e-2)\n","            gp.fit(X, y)\n","\n","            # Predict\n","            y_pred, sigma = gp.predict(X, return_std=True)\n","            y_pred_total.extend(y_pred)\n","\n","        gp_data.append(y_pred_total)\n","\n","    return np.array(gp_data).T\n","\n","# Run the interpolation process\n","df_interpolated = interpolate_with_gpr_batch(df, batch_size=10000)\n","df[:] = df_interpolated\n","df"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:27:34.272518Z","iopub.status.busy":"2024-09-23T12:27:34.272245Z","iopub.status.idle":"2024-09-23T12:27:34.294180Z","shell.execute_reply":"2024-09-23T12:27:34.293292Z","shell.execute_reply.started":"2024-09-23T12:27:34.272496Z"},"trusted":true},"outputs":[],"source":["# Step 2: Normalize the data\n","scaler = RobustScaler()\n","df_scaled = scaler.fit_transform(df)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:27:34.298675Z","iopub.status.busy":"2024-09-23T12:27:34.298333Z","iopub.status.idle":"2024-09-23T12:27:35.446492Z","shell.execute_reply":"2024-09-23T12:27:35.445598Z","shell.execute_reply.started":"2024-09-23T12:27:34.298646Z"},"trusted":true},"outputs":[],"source":["# Step 3: Initial Anomaly Detection using KNN\n","knn = KNN(contamination=0.03)\n","df['anomaly'] = knn.fit_predict(df_scaled)\n","df['anomaly'] = df['anomaly'].apply(lambda x: 1 if x == 1 else 0)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:27:35.447911Z","iopub.status.busy":"2024-09-23T12:27:35.447607Z","iopub.status.idle":"2024-09-23T12:27:41.741692Z","shell.execute_reply":"2024-09-23T12:27:41.740700Z","shell.execute_reply.started":"2024-09-23T12:27:35.447885Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(3853, 9)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Step 4: Identify Longest Span Without Anomalies\n","clean_spans = []\n","current_span = []\n","\n","for i in range(len(df)):\n","    if df['anomaly'].iloc[i] == 0:\n","        current_span.append(df.iloc[i])\n","    else:\n","        if len(current_span) > 0:\n","            clean_spans.append(pd.DataFrame(current_span))\n","            current_span = []\n","\n","if len(current_span) > 0:\n","    clean_spans.append(pd.DataFrame(current_span))\n","\n","longest_span = max(clean_spans, key=len).drop(columns=['anomaly'])\n","longest_span_scaled = scaler.transform(longest_span)\n","longest_span_scaled.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:27:41.743353Z","iopub.status.busy":"2024-09-23T12:27:41.742966Z","iopub.status.idle":"2024-09-23T12:27:41.754953Z","shell.execute_reply":"2024-09-23T12:27:41.754098Z","shell.execute_reply.started":"2024-09-23T12:27:41.743318Z"},"trusted":true},"outputs":[],"source":["# Step 5: Create Sliding Windows for Clean Data\n","def create_sliding_window(data, window_size):\n","    X = []\n","    for i in range(len(data) - window_size + 1):\n","        X.append(data[i:i + window_size])\n","    return np.array(X)\n","\n","window_size = 20\n","X_clean = create_sliding_window(longest_span_scaled, window_size)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:27:41.756646Z","iopub.status.busy":"2024-09-23T12:27:41.756267Z","iopub.status.idle":"2024-09-23T12:28:22.100721Z","shell.execute_reply":"2024-09-23T12:28:22.099905Z","shell.execute_reply.started":"2024-09-23T12:27:41.756614Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1727094467.537803     122 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["96/96 [==============================] - 6s 15ms/step - loss: 0.1014 - val_loss: 0.0829\n","Epoch 2/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0505 - val_loss: 0.0496\n","Epoch 3/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0417 - val_loss: 0.0537\n","Epoch 4/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0423 - val_loss: 0.0545\n","Epoch 5/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.0295\n","Epoch 6/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0233\n","Epoch 7/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0226 - val_loss: 0.0301\n","Epoch 8/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0227 - val_loss: 0.0237\n","Epoch 9/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0173\n","Epoch 10/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0297\n","Epoch 11/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0233 - val_loss: 0.0126\n","Epoch 12/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0178\n","Epoch 13/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0269\n","Epoch 14/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0186\n","Epoch 15/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0141\n","Epoch 16/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0114\n","Epoch 17/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0124 - val_loss: 0.0094\n","Epoch 18/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0223\n","Epoch 19/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0100\n","Epoch 20/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0157\n","Epoch 21/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0108\n","Epoch 22/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0119 - val_loss: 0.0132\n","Epoch 23/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0173\n","Epoch 24/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0181\n","Epoch 25/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0109\n","Epoch 26/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0117 - val_loss: 0.0184\n","Epoch 27/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0119 - val_loss: 0.0099\n","Epoch 28/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0113 - val_loss: 0.0103\n","Epoch 29/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0110 - val_loss: 0.0129\n","Epoch 30/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0160\n","Epoch 31/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0119\n","Epoch 32/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0113 - val_loss: 0.0151\n","Epoch 33/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0105 - val_loss: 0.0075\n","Epoch 34/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0133\n","Epoch 35/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0234\n","Epoch 36/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0100\n","Epoch 37/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0081\n","Epoch 38/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0093\n","Epoch 39/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0102 - val_loss: 0.0096\n","Epoch 40/50\n","96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0092\n","Epoch 41/50\n","96/96 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0148\n","Epoch 42/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0087\n","Epoch 43/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0093 - val_loss: 0.0087\n","Epoch 44/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0092 - val_loss: 0.0132\n","Epoch 45/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0096 - val_loss: 0.0081\n","Epoch 46/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0104\n","Epoch 47/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0107 - val_loss: 0.0100\n","Epoch 48/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0102 - val_loss: 0.0086\n","Epoch 49/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0094 - val_loss: 0.0110\n","Epoch 50/50\n","96/96 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0172\n"]}],"source":["# Step 6: LSTM Autoencoder\n","input_dim = longest_span_scaled.shape[1]\n","\n","input_layer = Input(shape=(window_size, input_dim))\n","lstm_layer = LSTM(90)(input_layer)\n","repeat_vector = RepeatVector(window_size)(lstm_layer)\n","lstm_output = LSTM(90, return_sequences=True)(repeat_vector)\n","output_layer = TimeDistributed(Dense(input_dim))(lstm_output)\n","\n","autoencoder_clean = Model(inputs=input_layer, outputs=output_layer)\n","autoencoder_clean.compile(optimizer='adam', loss='mse')\n","\n","X_clean_train = X_clean.reshape((X_clean.shape[0], window_size, input_dim))\n","history_clean = autoencoder_clean.fit(X_clean_train, X_clean_train, epochs=50, batch_size=32, validation_split=0.2, shuffle=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:28:22.102396Z","iopub.status.busy":"2024-09-23T12:28:22.102031Z","iopub.status.idle":"2024-09-23T12:28:22.110195Z","shell.execute_reply":"2024-09-23T12:28:22.109314Z","shell.execute_reply.started":"2024-09-23T12:28:22.102369Z"},"trusted":true},"outputs":[],"source":["class PolynomialRegression:\n","    def __init__(self, degree=2):\n","        self.degree = degree\n","        self.model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n","        self.X_train = []\n","        self.y_train = []\n","\n","    def fit(self, X, y):\n","        # Ensure that the model only keeps 15 values in the sliding window\n","        self.X_train = X[-15:]\n","        self.y_train = y[-15:]\n","        self.model.fit(self.X_train, self.y_train)\n","\n","    def predict_anomaly_time(self, threshold_value, current_time):\n","        try:\n","            # Predict the time until the threshold value is reached\n","            X_predict = np.array([[threshold_value]])  # Predict based on the threshold value\n","            predicted_time = self.model.predict(X_predict)[0][0]\n","            return predicted_time\n","        except Exception as e:\n","            print(e)\n","            return np.inf  # Return infinity in case of prediction error"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:28:22.111919Z","iopub.status.busy":"2024-09-23T12:28:22.111526Z","iopub.status.idle":"2024-09-23T12:28:22.122912Z","shell.execute_reply":"2024-09-23T12:28:22.121997Z","shell.execute_reply.started":"2024-09-23T12:28:22.111888Z"},"trusted":true},"outputs":[],"source":["# Step 7: Validate and Predict Anomalies on Full Data using Regression for Rate of Approach\n","# Compute the range and normal limits\n","upper_limit = np.max(longest_span_scaled, axis=0)\n","lower_limit = np.min(longest_span_scaled, axis=0)\n","range_value = upper_limit - lower_limit\n","normal_upper_limit = upper_limit + 0.5 * range_value\n","normal_lower_limit = lower_limit - 0.5 * range_value\n","anomaly_threshold = 1.5 * range_value"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T12:28:22.125170Z","iopub.status.busy":"2024-09-23T12:28:22.124875Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking from 2011-10-15 00:39:53.093501721 to 2011-10-15 06:57:35.893500925\n","\n","Checking from 2011-10-16 00:01:42.658140718 to 2011-10-16 23:59:54.158138534\n","\n","\tAnomaly detected at 2011-10-16 01:59:31.410147715\n","\n","\tAnomaly detected at 2011-10-16 03:34:50.935069823\n","\n","\tAnomaly detected at 2011-10-16 05:05:46.481966212\n","\n","\tAnomaly detected at 2011-10-16 15:16:20.772524627\n","\n","\tAnomaly detected at 2011-10-16 16:46:32.322963973\n","\n","\tAnomaly detected at 2011-10-16 19:48:38.083724583\n","\n","Checking from 2011-10-17 00:04:06.231204500 to 2011-10-17 22:10:51.331200500\n","\n","\tAnomaly detected at 2011-10-17 04:01:09.709990388\n","\n","\tAnomaly detected at 2011-10-17 07:13:33.604854904\n","\n","\tAnomaly detected at 2011-10-17 12:24:00.274635269\n","\n","Checking from 2011-10-18 00:08:22.262821658 to 2011-10-18 13:03:29.662818586\n","\n","\tAnomaly detected at 2011-10-18 06:48:02.646715073\n","\n","\tAnomaly detected at 2011-10-18 09:55:24.789924113\n","\n","\tAnomaly detected at 2011-10-18 12:03:39.029132327\n","\n","\tAnomaly detected at 2011-10-18 12:19:51.489273242\n","\n","\tAnomaly detected at 2011-10-18 12:46:13.146177301\n","\n","Checking from 2011-10-19 00:34:30.535182534 to 2011-10-19 23:56:30.135177705\n","\n","\tAnomaly detected at 2011-10-19 00:39:59.203274582\n","\n","\tAnomaly detected at 2011-10-19 04:56:53.181229600\n","\n","\tAnomaly detected at 2011-10-19 13:38:54.134016607\n","\n","\tAnomaly detected at 2011-10-19 15:08:11.232843127\n","\n","\tAnomaly detected at 2011-10-19 16:38:34.068837299\n","\n","\tAnomaly detected at 2011-10-19 18:59:53.393610849\n","\n","Checking from 2011-10-20 00:00:33.008715596 to 2011-10-20 23:59:43.808714732\n","\n","\tAnomaly detected at 2011-10-20 03:54:38.222883867\n","\n","Checking from 2011-10-21 00:00:00 to 2011-10-21 22:59:41.599995216\n","\n","\tAnomaly detected at 2011-10-21 01:53:51.820431179\n","\n","\tAnomaly detected at 2011-10-21 03:20:47.327985361\n","\n","\tAnomaly detected at 2011-10-21 04:55:46.061207375\n","\n","\tAnomaly detected at 2011-10-21 13:36:29.116599266\n","\n","\tAnomaly detected at 2011-10-21 15:05:21.264659375\n","\n","\tAnomaly detected at 2011-10-21 16:39:30.080858821\n","\n","\tAnomaly detected at 2011-10-21 19:23:21.171341664\n","\n","\tAnomaly detected at 2011-10-21 20:49:10.020736409\n","\n","Checking from 2011-10-22 00:03:43.570443060 to 2011-10-22 23:58:05.770440990\n","\n","\tAnomaly detected at 2011-10-22 02:04:24.778029558\n","\n","\tAnomaly detected at 2011-10-22 03:15:49.874583171\n","\n","\tAnomaly detected at 2011-10-22 04:46:30.093851600\n","\n","\tAnomaly detected at 2011-10-22 15:00:29.529127037\n","\n","\tAnomaly detected at 2011-10-22 15:23:53.056779545\n","\n","\tAnomaly detected at 2011-10-22 16:30:44.907708449\n","\n","\tAnomaly detected at 2011-10-22 18:07:12.892575901\n","\n","Checking from 2011-10-23 00:02:13.428443679 to 2011-10-23 23:59:03.028442944\n","\n","\tAnomaly detected at 2011-10-23 03:43:22.151646992\n","\n","\tAnomaly detected at 2011-10-23 05:19:44.050780219\n","\n","\tAnomaly detected at 2011-10-23 05:28:08.120866796\n","\n","\tAnomaly detected at 2011-10-23 16:58:45.057932016\n","\n"]}],"source":["predictions = []\n","predicted_timestamps = []\n","regression_models = [PolynomialRegression(degree=2) for _ in range(input_dim)]\n","\n","# Loop through each date and group\n","for date, group in df.groupby(df.index.date):\n","    last_index = group.index[-1]\n","    group_scaled = scaler.fit_transform(group)\n","    time_diffs = group.index.to_series().diff().dt.total_seconds().fillna(0)\n","    initial_window = group_scaled[:20, :-1].reshape((1, 20, input_dim))\n","    print(f\"Checking from {group.index[0]} to {last_index}\\n\")\n","    \n","    # Initialize for tracking anomalies and reset conditions\n","    last_anomaly_timestamp = None\n","    normal_period_duration = 0\n","    # Append initial predictions from the window\n","    for i in range(20):\n","        predictions.append(initial_window[0, i, :])\n","    \n","    # Main anomaly prediction loop\n","    for i in range(20, len(group)):\n","        window = np.array(predictions[-20:]).reshape((1, 20, input_dim))\n","        next_value = autoencoder_clean.predict(window, verbose=0)\n","        predictions.append(next_value[0, -1, :])\n","        current_time = group.index[i]\n","\n","        anomaly_detected = False\n","        for feature_idx in range(input_dim):\n","            current_value = group_scaled[i, feature_idx]\n","            n_upper_limit = normal_upper_limit[feature_idx]\n","            n_lower_limit = normal_lower_limit[feature_idx]\n","\n","            # Check for anomaly\n","            if (current_value > n_upper_limit) or (current_value < n_lower_limit):\n","                anomaly_detected = True\n","                normal_period_duration = 0  # Reset consecutive normal count for this feature\n","\n","                # Train regression on time diffs and corresponding values for this feature\n","                X_train = np.array(time_diffs[i-15:i].cumsum()).reshape(-1, 1)\n","                y_train = group.iloc[i-15:i, feature_idx].values.reshape(-1, 1)\n","\n","                # Fit the polynomial regression model\n","                regression_models[feature_idx].fit(X_train, y_train)\n","\n","                # Predict time to anomaly\n","                target = (n_upper_limit + anomaly_threshold[feature_idx] \n","                          if current_value > n_upper_limit \n","                          else n_lower_limit - anomaly_threshold[feature_idx])\n","                \n","                time_to_anomaly = regression_models[feature_idx].predict_anomaly_time(target, current_value)\n","\n","                # If valid time to anomaly is predicted\n","                if np.isfinite(time_to_anomaly) and 0 < time_to_anomaly < 10**5:\n","                    predicted_timestamp = current_time + pd.Timedelta(seconds=time_to_anomaly)\n","                    \n","                    # Update or append the anomaly timestamp for this feature\n","                    if last_anomaly_timestamp is None or (predicted_timestamp - last_anomaly_timestamp).total_seconds() >= 300:\n","                        predicted_timestamps.append(predicted_timestamp)\n","                        last_anomaly_timestamp = predicted_timestamp\n","                        print(f\"\\tAnomaly detected at {predicted_timestamp}\\n\")\n","                    elif predicted_timestamp < predicted_timestamps[-1]:\n","                        predicted_timestamps[-1] = predicted_timestamp\n","                        print(f\"\\tUpdated anomaly prediction to {predicted_timestamp}\\n\")\n","                    else:\n","                        last_anomaly_timestamp = predicted_timestamp\n","        # If no anomaly detected, reset regression models\n","        if not anomaly_detected:\n","            normal_period_duration += time_diffs[i]\n","                \n","            if normal_period_duration >= 300:\n","                regression_models = [PolynomialRegression(degree=2) for _ in range(input_dim)]\n","\n","        # Stop if current time has passed the last index for the day\n","        if current_time >= last_index:\n","            continue"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(predicted_timestamps)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Step 8: Visualize Results\n","predictions = pd.DataFrame(predictions)\n","num_features = df_scaled.shape[1]\n","fig, axes = plt.subplots(num_features, 1, figsize=(15, 5 * num_features), sharex=True)\n","\n","for i in range(num_features):\n","    axes[i].plot(df.index, df_scaled[:, i], label=f'Feature {i+1}')\n","    axes[i].plot(df.index, predictions[:][i], label=f'Prediction {i+1}')\n","    axes[i].scatter(df.index[df['anomaly'] == 1], df_scaled[df['anomaly'] == 1, i], color='red', label='Anomalies')\n","    for timestamp in predicted_timestamps:\n","        axes[i].axvline(x=timestamp, color='blue', linestyle='--')\n","    axes[i].set_title(f'Feature {i+1}')\n","    axes[i].legend()\n","\n","plt.xlabel('Datetime')\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5259847,"sourceId":8755705,"sourceType":"datasetVersion"},{"datasetId":5379155,"sourceId":8939972,"sourceType":"datasetVersion"},{"datasetId":5395956,"sourceId":8964484,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
